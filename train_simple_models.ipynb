{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model\n",
    "\n",
    "This is the code to train a simple model using keras. This seems to be unefficient, making a very complex and big CNN. However with no no more then 3500 images it converges well to almost 100% accuracy (on evaluation). Still only using, one model per person. Using only one type of attack.\n",
    "\n",
    "The need of a more robust method would be good. A model that can generilize from multiple people and corectly discriminate live faces from spoofed ones, form different attacks. That would require more and better models of style tranfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64bit', 'WindowsPE')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as Kb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "now_datetime  = datetime.datetime.now()\n",
    "NAME = f\"#Face_spoofing300x2_{now_datetime.day:02d}{now_datetime.month:02d}{now_datetime.year}_{now_datetime.hour:02d}{now_datetime.minute:02d}\"\n",
    "dir_pickle = \"database_serialized\"\n",
    "dir_models_save = \"models\"\n",
    "person = \"001\"\n",
    "import platform\n",
    "print(platform.architecture())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model format\n",
    "This is a simple CNN, that is made of a convolutional and a dense layer. below you choose the numbers of filters of each concolutional layer, and the numbers of neurons of each dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format of the convolutional layer\n",
    "format_convolutions = [[80,140,320],[80,140,320]]\n",
    "#format of the dense layer\n",
    "format_denses = [[400,300,200],[400,300,200]]\n",
    "\n",
    "NN_formats = (format_convolutions,format_denses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "The model creaeted here is enought for an almost ideal (acc = 98%) spoof detection model, as expected from a liveness detection methods that include deep learning as shown on many [studies](https://www.emerald.com/insight/content/doi/10.1108/SR-08-2015-0136/full/html) before.\n",
    "\n",
    "However the artifical creation of spoofed images, may reduce its performance. For 2 different reasons:\n",
    "1. Non perfect spoofed images. The creating of a model that can generate an spoofed image relayes much on the single image and the trainning data used to create such model. If both are not manage correctly, the creation of bad models may occur. Not to mention that some types of attacks are really hard to imitate e.g. print attacks.\n",
    "2. Reduced numbers of data. There isn't much data online for this type of problem, and it to the creation of individuals models for each person may prove unresenable, for each person must have minutes (about two) of video of their faces, for a better conversion of the CNN.\n",
    "\n",
    "For those reasons, it would be needed a deep leraning method that requires less data, to generalize. Something that could be accuired by [this](https://www.sciencedirect.com/science/article/pii/S1047320318301044) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(person):   \n",
    "    pickle_path =os.path.join(dir_pickle,person)\n",
    "    pickle_in = open(os.path.join(pickle_path,f\"X{person}.pickle\"),\"rb\")\n",
    "    X = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(os.path.join(pickle_path,f\"y{person}.pickle\"),\"rb\")\n",
    "    y = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    \n",
    "    X = X.astype(np.float16)/255.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_model(person, pickle_path,format_convolution,format_dense):\n",
    "    model = Sequential()\n",
    "    is_first = True\n",
    "    # Convolutional layers\n",
    "    for format_c in format_convolution:\n",
    "        if is_first:\n",
    "            model.add(layers.Conv2D(format_c,(3,3),input_shape=X.shape[1:]))\n",
    "            is_first = False\n",
    "        else:\n",
    "            model.add(layers.Conv2D(format_c,(3,3)))\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "        model.add(layers.MaxPool2D(pool_size=(3,3)))\n",
    "    #Flatten the model if needed\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    #Dense layers\n",
    "    for format_d in format_dense:\n",
    "        model.add(layers.Dropout(0.12))\n",
    "        model.add(layers.Dense(format_d,activation=\"relu\",kernel_regularizer=l2(0.002)))\n",
    "    \n",
    "    #Output layer\n",
    "    model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics= [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning your model\n",
    "This line trains your model. It is recoomend to use tensorflow-gpu, and to be carefull if your gpu can handle the data, if  you are having *ResourceExhaustedError*, try reducing the **batch size**, or the sizes of your **tesors**.\n",
    "\n",
    "Keep the eye on your **validation** because that shows your live performance without trainning bias. You may use checkpoints to get the best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(person,format_convolution,format_dense):\n",
    "    if not os.path.isdir(os.path.join(dir_models_save,person)):\n",
    "        os.mkdir(os.path.join(dir_models_save,person))\n",
    "    checkpoints = callbacks.ModelCheckpoint(filepath=os.path.join(dir_models_save,person,f\"{person}{NAME}{format_convolution}{format_dense}.h5\"),\n",
    "                                                monitor=\"val_acc\",\n",
    "                                                mode = \"max\",\n",
    "                                                verbose = 1,\n",
    "                                                save_weights_only=False,\n",
    "                                                save_best_only=True)\n",
    "    return checkpoints\n",
    "        \n",
    "def create_validation(person,val_test_split=0.25):\n",
    "    pickle_path =os.path.join(dir_pickle,person)\n",
    "    pickle_in = open(os.path.join(pickle_path,f\"X{person}Test.pickle\"),\"rb\")\n",
    "    Xval = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(os.path.join(pickle_path,f\"y{person}Test.pickle\"),\"rb\")\n",
    "    yval = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    Xval = Xval.astype(np.float16)\n",
    "    Xval = Xval/255.0\n",
    "    yval = yval\n",
    "    ValSet = [Xval,yval]\n",
    "    random.shuffle(ValSet)\n",
    "    n_exs = len(ValSet[0]) * val_test_split\n",
    "    return ValSet[:int(n_exs)-1][:int(n_exs)-1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10635 samples, validate on 1156 samples\n",
      "Epoch 1/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9847\n",
      "Epoch 00001: val_acc improved from -inf to 0.99048, saving model to models\\001\\001#Face_spoofing300x2_12102019_1549[80, 140, 320][80, 140, 320].h5\n",
      "10635/10635 [==============================] - 171s 16ms/sample - loss: 0.1370 - acc: 0.9847 - val_loss: 0.0478 - val_acc: 0.9905\n",
      "Epoch 2/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9860- \n",
      "Epoch 00002: val_acc improved from 0.99048 to 1.00000, saving model to models\\001\\001#Face_spoofing300x2_12102019_1549[80, 140, 320][80, 140, 320].h5\n",
      "10635/10635 [==============================] - 175s 16ms/sample - loss: 0.1462 - acc: 0.9860 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 3/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9970\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "10635/10635 [==============================] - 161s 15ms/sample - loss: 0.0394 - acc: 0.9970 - val_loss: 0.1172 - val_acc: 0.9862\n",
      "Epoch 4/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9950\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n",
      "10635/10635 [==============================] - 162s 15ms/sample - loss: 0.0495 - acc: 0.9950 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 5/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9987\n",
      "Epoch 00005: val_acc did not improve from 1.00000\n",
      "10635/10635 [==============================] - 161s 15ms/sample - loss: 0.0295 - acc: 0.9987 - val_loss: 0.0303 - val_acc: 1.0000\n",
      "Epoch 6/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9945\n",
      "Epoch 00006: val_acc did not improve from 1.00000\n",
      "10635/10635 [==============================] - 164s 15ms/sample - loss: 0.0369 - acc: 0.9944 - val_loss: 0.3577 - val_acc: 0.9844\n",
      "Epoch 7/7\n",
      "10632/10635 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9911- ETA: 1s - loss: 0.0366 - \n",
      "Epoch 00007: val_acc did not improve from 1.00000\n",
      "10635/10635 [==============================] - 164s 15ms/sample - loss: 0.0364 - acc: 0.9911 - val_loss: 0.0144 - val_acc: 0.9991\n",
      "Train on 10635 samples, validate on 1156 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6,400,99,99] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Adam_1/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6d40d054adf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#Split the serilized test to validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mValSet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mValSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\face_spoofing\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6,400,99,99] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Adam_1/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "people = os.listdir(dir_pickle)\n",
    "for person in people:\n",
    "    X, y = load_data(person)\n",
    "    ValSet = create_validation(person)\n",
    "    for format_convolution, format_dense in NN_formats:\n",
    "        # Create the model structure for the person\n",
    "        model = create_model(person,os.path.join(dir_pickle,person),format_convolution,format_dense)\n",
    "        checkpoint = create_callbacks(person,format_convolution,format_dense)\n",
    "        #Split the serilized test to validation\n",
    "        #Train model\n",
    "        model.fit(X,y,batch_size=6,validation_data=ValSet,epochs=4,shuffle=False, callbacks=[checkpoint])\n",
    "    del X,y,ValSet,model\n",
    "    Kb.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kills the kernel to free-up memory on GPU, also avoiding collisions with othhers scripts \n",
    "#comment the line below, if you want to keep the variables and buffers\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_spoofing",
   "language": "python",
   "name": "face_spoofing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
